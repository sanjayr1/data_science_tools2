* Data Science Tools 2
  - Course: Data Science Project 2  COMP 4448 2
  - Class time: M, Wed  07:00 PM -  08:50 PM  |Engineering & Computer Science | Room 301
  - Instructor: /Pooran Singh Negi, pooran.negi@du.edu/ [[https://sites.google.com/site/poorannegi/][webpage]]
  - Office: 470
  - Office Hours: Mon, Wed,  4. p.m. - 5.30 p.m. Email for 1-on-1 help.
  - GTA: Shaswat Sharma, shaswat.sharma@du.edu, 2-4 p.m Thu, Fri,  ECS 365 breakout room
   
** Optional Books 
   - [[https://www.amazon.com/Python-Data-Analysis-Wrangling-IPython/dp/1491957662/ref=sr_1_2?s=books&ie=UTF8&qid=1522206082&sr=1-2&keywords=pandas][Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython 2nd Edition]]  by Wes McKinney. It is available online from [[https://library.du.edu/][library]]
   - [[http://greenteapress.com/thinkstats2/html/index.html][Think Stats: Exploratory Data Analysis in Python]]
   -[[http://greenteapress.com/wp/think-bayes/][ Think Bayes]]  
   - [[http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/][Probabilistic Programming & Bayesian Methods for Hackers]]
   - [[https://du-primo.hosted.exlibrisgroup.com/primo-explore/fulldisplay?docid=01UODE_ALMA51971778520002766&context=L&vid=01UODE_MAIN&lang=en_US&search_scope=everything_scope&adaptor=Local%2520Search%2520Engine&tab=default_tab&query=any,contains,Mastering%2520Python%2520Regular%2520Expressions%2520&sortby=rank&mode=Basic][Mastering Python Regular Expressions]] by  Félix López  (Author), Víctor Romero 
   
     more to come
** Optional material online
 - [[https://radimrehurek.com/gensim/tutorial.html][Gensim tutorials]]

 - [[https://www.machinelearningplus.com/nlp/gensim-tutorial/][Gensim Tutorial – A Complete Beginners Guide]] shared by Logan Register
 - [[https://www.plotly.express/][plotly express:a terse, consistent, high-level wrapper around Plotly.py for rapid data exploration and figure generation]]
* Course Description
It is recommended that you consult this github page often for material related to this course. You should check your e-mail periodically for messages.
Assignments will be upload here and in the [[https://canvas.du.edu/login/ldap][canvas]].

We'll continue data science life cycle after data cleanup and summarization. The main objective of data science tools 2 is to learn various tools to perform data analysis.
Primary focus in tools 2 is statistical testing, feature engineering and
building effective predictive models. We'll use [[http://jupyter.org/][jupyter notebook/lab]] for in the class and homeworks assignments.

For the final project, students will work through  individual or team projects applying course-work.
to the  data lifecycle within a particular domain. The focus will also be
on best data science/software engineering practices and reproducible work.

*Please start looking for  a project. You are allowed to have a group of 2 to 3 students but project work must justify team count.* There will be a homework asking about the detail of your final project. We'll provide feedback about feasibility of the final project.
*Final project, can be based on initial data science tool1 work or capstone work?. Please let us know if this is the case. We need to go over details.*

*** Project proposal
Not graded. Any team member can submit this. Main focus in tools 2 is building predictive models.
 - Team members. Justification for 2 and 3 team members .
 - Problems/Motivation.
 - What libraries/tools you will need. What you already know and what else you need to evaluate.
 - Data Collection details.
 - Any Literature review.
 - Required work detail before build model(clean up, hypothesis, data bias analysis etc.).
 - What is the predictive task and model detail. Model evaluation and selection strategy.
 - How a user is going to test the final model. is there any webpage/command line interface. It can be like using *curl* from command line and calling a function(lambda via API gateway) in the cloud(AWS).
 - Tentative time line of activities.


*We'll ask about project progress throughout the course work* 

** Syllabus
*This syllabus is subject to change at the discretion of the instructor*.
- Statistical testing
- Feature engineering
- NLP word representation
- Time series analysis
- Cloud computing basics(AWS EC2, S3, IAM etc.)
- Severless computing, AWS lambda (may be will use Alexa skill), building REST API etc.
- Stats model for linear regression
- statsmodels and sklearn for logistic regression
- model evaluation and selection

 *Linux command line and scientific python ( primarily numpy, statsmodels, sklearn, matplotlib, request, seaborn, basic pandas) will be used throughout the course.*

* Grading
*There will be  coding/analysis homework assignments, midterm and a final project. We'll drop one of your worst assignment grade*.
We'll allow 2 late homework with cutoff of 36 hours. We'll give *ceil(total_marks_obtained*exp(-(minutes late)/(24*60)))* marks  for  late submitted assignments via email.
There will be a final presentation of the final project.
You will be required to  submit a project plan document and a final project report in the jupyter notebook format.

** [[./project_presentation.org][project project presentation grading  rubric]]
** [[./project_rubric.org][final project report grading rubric]]

** Dates

|---------------------------------------------------------------------------------------------------------+-----|
| coding Homework                                                                                         | 35% |
|---------------------------------------------------------------------------------------------------------+-----|
| Midterm, 8 th May in class                                                                              | 25% |
|---------------------------------------------------------------------------------------------------------+-----|
| Final project presentation, 8 minutes, 5th June in class                                                | 10% |
|---------------------------------------------------------------------------------------------------------+-----|
| Final project report, due 5 th June, please refer to above final report format for submission guideline | 30% |
|---------------------------------------------------------------------------------------------------------+-----|
|                                                                                                         |     |

** Final course grading rubric

grade range [('A', >=93), ('A_minus', >=89), ('B_plus', >=85), ('B', >=81), ('B_minus', >=77), ('C_plus', >=73), ('C', >=69), ('C_minus', >=65),
 ('D_plus', >61), ('D', >=57), ('D_minus', >=53),  ('F', < 53)])

 
* Honor code
All members of the University of Denver community are expected to uphold the values of Integrity, Respect, and Responsibility.
These values embody the standards of conduct for students, faculty, staff, and administrators as members of the University community. 
Our institutional values are defined as:

Integrity: acting in an honest and ethical manner;

Respect: honoring differences in people, ideas, experiences, and opinions;

Responsibility: accepting ownership for one's own behavior and conduct.

Please respect DU [[https://www.du.edu/studentlife/studentconduct/honorcode.html][Honor Yourself, Honor the Code]]

* Students with Disabilities
Students with recognized disabilities will be provided reasonable
accommodations, appropriate to the course, upon documentation of the disability with a Student
Accommodation Form from the Disability Services Program. *To receive these accommodations, you must request the specific accommodations, by submitting them to the instructor in writing,
by the end of first week of classes.* Visit [[https://www.du.edu/studentlife/disability/][CAMPUS LIFE & INCLUSIVE EXCELLENCE]] webpage for details.

* Withdrawal Policy
Please see [[https://www.du.edu/registrar/calendar/][registrar calender]] for Academic deadlines. *We'll strictly follow the deadlines.*

* Data set for Projects
  - Web scraping, web API (for natural language processing one can use the New York Times, twitter etc.)
  - [[https://github.com/awesomedata/awesome-public-datasets][awesome-public-datasets]]
  - [[https://www.kdnuggets.com/datasets/index.html][Datasets for Data Mining and Data Science]]
  - [[http://data.europa.eu/euodp/en/about][The EU Open Data Portal]]
  - [[https://data.worldbank.org/][World Bank Open Data]]
  - [[https://www.data.gov/][The home of the U.S. Government’s open data]]
 
 We need to know your project/dataset, before we approve it for final project. 

 More to come.
     
* Software Installation
** Python
We want everybody to have same experience using computational tools in data science tools 1. Please follow steps as
per your operating system.

*** Window based installation
Please install Windows Subsystem for Linux (WSL) on window 10. Follow the instruction in this post [[https://medium.com/hugo-ferreiras-blog/using-windows-subsystem-for-linux-for-data-science-9a8e68d7610c][Using Windows Subsystem for Linux for Data Science]]
by Hugo Ferreira for installing Linux. **ignore install Anaconda part.**

You can also watch this [[https://www.youtube.com/watch?v=Cvrqmq9A3tA][video]] to see installation of Windows 10 Bash & Linux Subsystem Setup.
** Linux /Mac users should already have bash command prompt
You can run *echo $0* to check current shell. Change to bash shell using  *chsh -s /bin/bash*

*One you are in Linux/Mac bash command prompt, Please follow following instructions*
** Python3 installation
Please follow instructions [[https://realpython.com/installing-python/][here]] to install python3 if it is not installed in your system. This link
also lists Windows Subsystem for Linux (WSL) for window 10(Windows 10 Creators or Anniversary Update).
I am using python 3.5.2. Hopefully any version of python 3 should work.

*** creating virtual environment and installing packages for data science tools 1
*Run following commands from  command prompt.*

- *apt-get install python3-venv*
- Using command line(*cd command*), go to the folder where you want to keep python file, notebooks related to this course.
- run *python3 -m venv /path/to/new/virtual/environment*
  + e.g. I ran *python3 -m venv dst1_env*
- To activate your environment run *source /path/to/new/virtual/environment/bin/activate*
  + e.g From this course directory I run, *source dst1_env/bin/activate*

- run *python3 -m pip install \-\-upgrade pip*. Note that there are 2 dashes in upgrade option.
- run *wget https://raw.githubusercontent.com/psnegi/data_science_tools1/master/requirements.txt*
- run *pip install -r requirements.txt*
- run *jupyter notebook* or *jupyter lab*. 
- In the browser you should see your current files.
- Click on the notebook you want to run.

- click on *RISE* slideshow extension in notebook, if you want to see notebook as slideshow.

To deactivate  python virtual environment, run *deactivate*

*** Python learning resources
You can also go to my  [[https://github.com/psnegi/PythonForReproducibleResearch][python for reproducible research]]  github repository and start by running pythonBasic.ipynb notebook.
I will go over basic of python and jupyter notebook.

   - [[https://try.jupyter.org/][try python notebook online without installing anything]]
   - [[http://pythontutor.com/live.html#mode%3Dedit][Runs and visualizes your python code]]
   - [[https://docs.python.org/3/tutorial/index.html][The Python Tutorial]]  
*** data analysis tools in python
  - more to come

* Notebooks
** April 1 
- [[https://mybinder.org/v2/gh/psnegi/data_science_tools2/master?filepath=notebooks/hypothesis_testing.ipynb][hypothesis testing]]
** April 3
- [[https://mybinder.org/v2/gh/psnegi/data_science_tools2/master?filepath=notebooks/feature_engineering.ipynb][feature engineering]]
** April 8 
-  [[https://mybinder.org/v2/gh/psnegi/data_science_tools2/master?filepath=notebooks/feature_selection.ipynb][feature selection]]

** 15 April
-  [[https://mybinder.org/v2/gh/psnegi/data_science_tools2/master?filepath=notebooks/cloud_computing.ipynb][cloud, IAM , S3]]
** April 18 th
  *Stop the EC2 and notebook instance after use. Free tier has limit on hour etc.*
  -  [[./notebooks/cloud_computing_roles_webserver.ipynb][cloud EC2, role etc.]]
  -  [[./notebooks/aws_machine_learning.ipynb][SageMaker sample notebook]]
** April 22
  -  [[https://mybinder.org/v2/gh/psnegi/data_science_tools2/master?filepath=notebooks/sklearn_data_analysis_pipeline.ipynb][sklearn_data_analysis_pipeline]]
** April 24
  -  [[https://mybinder.org/v2/gh/psnegi/data_science_tools2/master?filepath=notebooks/sklearn_outlier_validation.ipynb][sklearn_outlier_validation]]
  -  [[https://mybinder.org/v2/gh/psnegi/data_science_tools2/master?filepath=notebooks/sklearn_outlier_validation_inclass.ipynb][sklearn_outlier_validation in class version]]

** April 29
   -  [[https://mybinder.org/v2/gh/psnegi/data_science_tools2/master?filepath=notebooks/sklearn_data_analysis_data_validation_regression.ipynb][sklearn regression and model selection]]
   -  [[https://mybinder.org/v2/gh/psnegi/data_science_tools2/master?filepath=notebooks/sklearn_data_analysis_data_validation_regression_inclass.ipynb][sklearn regression and model selection in class]]
** May 1 st
    -  [[https://mybinder.org/v2/gh/psnegi/data_science_tools2/master?filepath=notebooks/sklearn_cross_validation.ipynb][sklearn kflold and grid search and custom loss functions]]
    -  [[https://mybinder.org/v2/gh/psnegi/data_science_tools2/master?filepath=notebooks/sklearn_cross_validation_inclass.ipynb][sklearn kflold and grid search and custom loss functions in class]]
** May 13
   -     -  [[https://mybinder.org/v2/gh/psnegi/data_science_tools2/master?filepath=notebooks/sklearn_custom_loss_function_cont.ipynb][n gram and custom loss]]
* Homeworks
*No late hw will be accepted*

|-------+-----------------------+------------------------------------------------------------------+----------|
| HW no |                       | description and links                                            | solution |
|       | Due date              |                                                                  |          |
|-------+-----------------------+------------------------------------------------------------------+----------|
|-------+-----------------------+------------------------------------------------------------------+----------|
|     1 | 14 th April 11.59 p.m | [[./hws/HW1_word_embedding.ipynb][word embedding]]                                                   | [[./hws/text_embedding.ipynb][sol key]]  |
|-------+-----------------------+------------------------------------------------------------------+----------|
|     - | poject proposal       |                                                                  |          |
|-------+-----------------------+------------------------------------------------------------------+----------|
|     2 | 2nd May   11.59 p.m   | [[./hws/HW2_feature_engineering_questions.ipynb][feature engineering and association between categorical variable]] | [[./hws/HW2_feature_engineering_sol.ipynb][sol key]]  |
|-------+-----------------------+------------------------------------------------------------------+----------|
|     3 | 8 th May 11 a.m.      | [[./hws/HW3_model_selection_and_evaluation.ipynb][model selection and evaluation]]                                   |          |
|       |                       |                                                                  |          |
|-------+-----------------------+------------------------------------------------------------------+----------|
|     4 | 19 May 11.59          | Please check your email for hw notebook                          |          |

* Midterm
   

* Course Activity

| Date        | Reading/Coding Assignments            | class activity                                                                                                                                          |
|-------------+---------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------|
|-------------+---------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------|
| 1 - April   | see the notebook                      | Reviewed basics of hypothesis testing framework.                                                                                                        |
|             |                                       | Please make sure you check all the assumption of a test before using it.                                                                                |
|             |                                       | Also start looking for dataset for the final project. There will be an assignment asking for project proposal                                           |
|             |                                       |                                                                                                                                                         |
|-------------+---------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------|
|-------------+---------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------|
| 3rd April   | see the notebook in notebook section  | handling categorical attributes, creating features from text using count vector, TF-IDF features,                                                       |
|             |                                       | neural embedding(GloVe vectors in $\mathbb{R}^d$ for words). For numerical attributes using some transformation of attributes(basis function expansion) |
|             |                                       | polynomial features etc.                                                                                                                                |
|-------------+---------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------|
| 8 th April  |                                       | feature selection method, filter , wrapper, embedded,                                                                                                   |
|             |                                       | t-SNE projection overview, create account at https://aws.amazon.com/free/ for starting cloud computing                                                  |
|             |                                       | See this new [[https://allennlp.org/elmo][ELMO]] word representation too                                                                                                               |
|-------------+---------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------|
| 15 th April |                                       | Basics of cloud computing, Why AWS? Covered *IAM* (Security ) And *S3* (storage classes and static web hosting)                                         |
|-------------+---------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------|
| 17 th April | see the notebooks in notebook section | EC2, command line, Sage maker                                                                                                                           |
|             |                                       |                                                                                                                                                         |
|-------------+---------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------|
|-------------+---------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------|
| 22 April    |                                       | feature engineering and dimensionality reduction using sklearn.                                                                                         |
|-------------+---------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------|
|-------------+---------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------|
| 24 th April |                                       | Multi variate outlier detection and validating classification model using sklearn                                                                       |
|-------------+---------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------|
| 29 th April |                                       | metrics for regression problems. model selection and evaluation.                                                                                        |
|-------------+---------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------|
| 1 st May    |                                       | cross validation iterator, KFold, Stratified KFold, entropy, cross entropy and custom loss functions                                                    |
|-------------+---------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------|
| 6 May       |                                       | Loss function. [[https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#cross-entropy][cross entropy]], weighted loss, infogain loss matrix, [[https://arxiv.org/pdf/1708.02002.pdf][Focal loss]].                                                                          |
|-------------+---------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------|
|             |                                       |                                                                                                                                                         |
