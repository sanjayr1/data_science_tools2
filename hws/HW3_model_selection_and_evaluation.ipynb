{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework we will build a survival prediction model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "%matplotlib inline\n",
    "sns.set(style=\"darkgrid\")\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_clean_df = pd.read_csv('https://raw.githubusercontent.com/psnegi/datasets/master/titanic/cleaned_titanic.csv')\n",
    "\n",
    "titanic_clean_df.head()\n",
    "\n",
    "titanic_clean_df = pd.concat([titanic_clean_df, pd.get_dummies(titanic_clean_df.Embarked, prefix =\"Embarked\")], axis=1)\n",
    "\n",
    "titanic_clean_df.drop(labels=['Embarked'], axis= 1, inplace= True)\n",
    "\n",
    "# removing Unnamed\n",
    "titanic_clean_df.drop(labels=['Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "titanic_clean_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titanic_clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_clean_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titanic_clean_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x= 'Survived', kind='count', data=titanic_clean_df )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly dataset in unbalanced from Survival prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can get a quick idea about observations count for dummy variables\n",
    "titanic_clean_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_clean_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on above summation result, we are removing some of the dummy attributes as there are not enough observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns= ['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare','Title_Master.',\n",
    "       'Title_Miss.','Title_Mr.', 'Title_Mrs.','Cabin_type_A',\n",
    "       'Cabin_type_B', 'Cabin_type_C', 'Cabin_type_D', 'Cabin_type_E',\n",
    "       'Cabin_type_F','Cabin_type_O' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_clean_df = titanic_clean_df[selected_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_clean_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_X = titanic_clean_df.drop(labels=['Survived'], axis= 1)\n",
    "titanic_y = titanic_clean_df['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 (.5 points) Using sklearn, divide dataset(titanic_X, titanic_y) in train  and test set with proportion .8, and .2 respectively. Set random state random state= 2 during split. Maintain Survived proportion in the train and test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y =  # Remove # and write code here"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2.(.5 points) Verify that train and test have roughly the same proportion of Survived =1 and =0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3(.5 pointd)Based on survival proportion in the dataset, what is the base accuracy you want to exceed by building a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4 (1) Use GridSearchCV for finding the best hyper parameters of  SVC (support vector classifiers, with kernel *poly*, *rbf*, *linear*). select the best model for survival prediction. Use gamma and C as defined below.\n",
    "\n",
    "Later in the course, we'll see how to use sklearn pipeline for optimizing over multiple classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This may take sometime.\n",
    "# Use google colab if it is taking a lot of time in your laptop.\n",
    "gamma = np.linspace(1e-2,1e-4, 2)\n",
    "print(gamma)\n",
    "\n",
    "C= np.linspace(1, 1000, 2)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameters = [{'kernel': ['rbf'], 'gamma': gamma,\n",
    "                     'C': C},\n",
    "                    {'kernel': ['linear'], 'C': C}]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5 (.5) Print best selected estimator(SVC with right hyper parameters) and evaluation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6 (1 point) Search of best model using RandomizedSearchCV. Report best model and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's increase the grid  search size\n",
    "# This may take sometime.\n",
    "# Use google colab if it is taking a lot of time in your laptop.\n",
    "gamma = np.linspace(1e-2,1e-4, 1)\n",
    "C= np.linspace(0.01, 1000, 1)\n",
    "hyper_parameters = {'kernel': ['rbf', 'linear'], 'C':C, 'gamma':gamma}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's use Isolation forest for outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_clean_df = pd.read_csv('https://raw.githubusercontent.com/psnegi/datasets/master/titanic/cleaned_titanic.csv')\n",
    "\n",
    "titanic_clean_df.head()\n",
    "\n",
    "titanic_clean_df = pd.concat([titanic_clean_df, pd.get_dummies(titanic_clean_df.Embarked, prefix =\"Embarked\")], axis=1)\n",
    "\n",
    "titanic_clean_df.drop(labels=['Embarked'], axis= 1, inplace= True)\n",
    "\n",
    "# removing Unnamed\n",
    "titanic_clean_df.drop(labels=['Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "titanic_clean_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_X = titanic_clean_df.drop(labels=['Survived'], axis= 1)\n",
    "titanic_y = titanic_clean_df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = titanic_clean_df.shape[0]\n",
    "outliers_fraction = 0.01\n",
    "n_outliers = int(outliers_fraction * n_samples)\n",
    "n_inliers = n_samples - n_outliers\n",
    "print (n_outliers, n_inliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 7(.5 points) Use IsolationForest for detecting multi variate outlier  in titanic_X. Use contamination as per above n_outliers calculation and random_state =3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "iosfo_outlier_detector = # Write code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iosfo_outlier_detector.fit(titanic_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inliner = iofo_outlier_detector.fit_predict(titanic_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what dummy variable have zero count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_X[inliner == -1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_X = titanic_X[inliner == 1]\n",
    "titanic_y = titanic_y[inliner == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titanic_X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove Title_Lady. as it has zero observation.\n",
    "titanic_X.drop(labels=['Title_Lady.'], axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_X.shape, titanic_y.shape, titanic_clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_X.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's work with these inliers only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8 (1.5) Split titanic_X, titanic_y into train_X, test_X, train_y, test_y using using train_test_split function and test_size= .2, random_state= 2. Maintain the survival proportion during split. Use GridSearchCV and following hyper parameters to find best model. Report your evaluation of the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = np.linspace(1e-2,1e-4, 2)\n",
    "print(gamma)\n",
    "\n",
    "C= np.linspace(1, 1000, 2)\n",
    "print(C)\n",
    "hyper_parameters = [{'kernel': ['rbf'], 'gamma': gamma,\n",
    "                     'C': C},\n",
    "                     {'kernel': ['linear'], 'C': C}]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Write code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
