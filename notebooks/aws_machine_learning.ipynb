{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for building machine learning model\n",
    "- Generally we need lot of data point(~ 10 times number of features)\n",
    "- Consistent data not many missing or null values\n",
    "- Unbiased sampled data\n",
    "\n",
    "We know that collecting and cleaning the data is the most important and time consuming step in the whole machine learning cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where to store data in the cloud\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing(input/output) data for machine learning\n",
    "- S3 (simple storage service. Most commonly used in machine learning)\n",
    "    + Check last lecture about what is S3\n",
    "         + Can use interface for uploading/command line in EC2/ or sdk\n",
    "         \n",
    "For machine learning we need to keep data in S3 but your data can be in of the following\n",
    "storage format.         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database solutions\n",
    "Transactional nature\n",
    "- RDS\n",
    "    + SQL\n",
    "    + MySQL\n",
    "    + PostgreSQL\n",
    "    + Aurora\n",
    "    + Oracle\n",
    "    \n",
    "https://aws.amazon.com/rds/    \n",
    "- No SQL\n",
    "    + DynamoDB\n",
    "    \n",
    "- Streaming data sources\n",
    "     - Use Kensis(Data Stream, Data Firehose, Video streams, Data Analytics )    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataware  housing\n",
    "- Amazon RedShift for analytics processing. Business queries, BI tools(SAP NetWeaver, Cognos).\n",
    "    + Stores petabytes or exabytes\n",
    "    + Typically some preprocessing is done\n",
    "    \n",
    "# Data Lake\n",
    "    + Raw, unstructured data with no preprocessing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Migration tool to get data in S3\n",
    " - Data pipeline\n",
    " - DMS(Data migration service)\n",
    " - AWS Glue(supports ETL(extract, transform and load))\n",
    "\n",
    "In this class, if you are using AWS then most probably you are uploading data to S3 bucket\n",
    "directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection - labeling\n",
    "If data is missing label for machine learning training then one can use\n",
    "  - Amazon SageMaker and Mechanical turk\n",
    "        + Help in tagging/labeling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sage maker\n",
    "- Login to aws console \n",
    "- Go to service and select sage maker\n",
    "- Select create notebook instance\n",
    "    + In next screen give name to notebook\n",
    "    + Keep instance type to m1.l2.medium\n",
    "    + In Permissions and encryption\n",
    "        + Create a new IAM role and add an S3 bucket(You may have to create it before using Sage maker)\n",
    "    + In Network\n",
    "        + **VPC - optional**, choose default\n",
    "        + **Subet** - Choose any\n",
    "        + **Security group** choose defaults\n",
    "        \n",
    "        \n",
    "These steps should create a notebook instance and **status** should change to **In service**. From action click **open jupyter notebook or lab**. We should have a jupyter server for creating notebook for data science or machine learning.\n",
    "\n",
    "See the sample notebook for the detail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check https://registry.opendata.aws/ for more Data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
